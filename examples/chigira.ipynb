{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and cointegration\n",
    "This article outlines the relation between Principal Component Anlaysis (PCA) and cointegration based on Chigira (2008). \n",
    "\n",
    "Recall that a prerequisite of cointegrated series is that every series has to be integrated of the same order. Let's denote <a href=\"https://en.wikipedia.org/wiki/Order_of_integration\">I(d)</a> for integration of order d. This means after d times of taking difference (i.e. $x_{t} - x_{t-1}$), the series becomes <a href=\"https://en.wikipedia.org/wiki/Stationary_process#Weak_or_wide-sense_stationarity\">(_weak_) stationary</a>. For simplicity, we will explore the case of I(1) series only here. In this case, cointegration simply says that there exists a linear combination of these integrated series such that the combination is stationary.\n",
    "\n",
    "Further recall that <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">(_linear_) Principal Component Analysis</a> seeks to find a set of vectors that maximize the variance after the vectors are applied as weights to the original series. What immediately follows from this is:\n",
    "- The maximized variance is the eigenvalue of the eigen-decomposition of the variance-covariance matrix of the original data. \n",
    "- The eigenvectors are the weights. These vectors may also be known as _**factor loading**_ in other fields of studies.\n",
    "- A principal component is the linear combination of the original series with eigenvectors as the weights.\n",
    "- The 2nd (or 3rd, 4th, ...) largest variance is the eignvalue of the variance-covariance matrix based on the residual data that the previous principal component(s) cannot explain. \n",
    "- Because these eigenvectors are orthgonal (the dot product of any two is 0), the principal components are orthogonal as well.\n",
    "- The <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">sklearn's PCA</a> implmentation produces orthonormal eigenvectors, meaning they are of unit length on top of being orthogonal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chigira (2008) proved that if the last few principal components are stationary, the original data are in fact cointegrated, provided each series is I(1). Furthermore, the number of stationary principal components equals the number of cointegration vectors (e.g. the eigenvectors from PCA).\n",
    "\n",
    "Let $\\pmb{x}_{t}=[x^1_t, x^2_t, ..., x^l_t ]^\\prime$ denote a vector of variables from $x^1$ to $x^l$ at time period $t$, properly demeaned and detrended. Just as Chigira (2008), we use a VAR model with a constant and time trend and no lag to model out the mean and trend:\n",
    "\\begin{equation}\n",
    "    \\pmb{y}_t = \\mu + \\sigma t + \\pmb{x}_{t}\n",
    "\\end{equation}\n",
    "where $\\pmb{x}_{t}$ is simply the residual of VAR on the original series $\\pmb{y}_t$.\n",
    "\n",
    "Let $\\pmb{\\Beta} = [ \\pmb{v}_1, ... , \\pmb{v}_m]$ be an $m$ by $l$ matrix of PCA eigenvectors, where $m$ is the intended number of principal components to keep. Thus $m \\le l$. The columns of $\\pmb{\\Beta}$ are ordered in descendingly according to the eigenvectors' eigenvalues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\pmb X$ denote an $n$ by $l$ matrix of data. Each column represents a time series. Each row represents a time period. \n",
    "\n",
    "\\begin{equation}\n",
    "    \\pmb{\\Beta} = \n",
    "    \\begin{bmatrix}\n",
    "            \\pmb{v}_1\\\\\n",
    "            \\pmb{v}_2\\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.007,  0.017,  0.386,  0.423, -0.081],\n",
       "       [-0.01 ,  0.023,  0.544,  0.595, -0.114],\n",
       "       [-0.368, -0.641, -0.478,  0.47 ,  0.072],\n",
       "       [ 0.   , -0.001, -0.018, -0.019,  0.004],\n",
       "       [-0.489, -0.483,  0.532, -0.49 , -0.074],\n",
       "       [-0.559,  0.426,  0.039,  0.074,  0.707],\n",
       "       [-0.556,  0.417, -0.204,  0.029, -0.686]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([\n",
    "    [-0.007, 0.017, 0.386, 0.423, -.081]\n",
    "    , [-.01, .023,.544,.595,-.114]\n",
    "    , [-.368, -.641, -.478, .47, .072]\n",
    "    , [0, -.001, -.018, -.019, .004]\n",
    "    , [-.489, -.483, .532, -.49, -.074]\n",
    "    , [-.559, .426, .039, .074, .707]\n",
    "    , [-.556, .417, -.204, .029, -.686]\n",
    "])\n",
    "# a = np.array([[-.77,.27], [.557, -.161], [0,0], [.313,.949]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.963110e-01,  1.740000e-03, -7.630000e-04,  2.490000e-04,\n",
       "        -2.400000e-03],\n",
       "       [ 1.740000e-03,  1.000354e+00,  8.000000e-05, -8.800000e-05,\n",
       "         7.070000e-04],\n",
       "       [-7.630000e-04,  8.000000e-05,  9.999010e-01, -1.070000e-03,\n",
       "         3.790000e-04],\n",
       "       [ 2.490000e-04, -8.800000e-05, -1.070000e-03,  1.000632e+00,\n",
       "         3.550000e-04],\n",
       "       [-2.400000e-03,  7.070000e-04,  3.790000e-04,  3.550000e-04,\n",
       "         1.000678e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T.dot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Chigira, H. (2008). A test of cointegration rank based on principal component analysis. Applied Economics Letters, 15(9), 693-696."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a8c18aa56161141526e07de135335298a5531f7dc7735f1e3196172a1afc09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
